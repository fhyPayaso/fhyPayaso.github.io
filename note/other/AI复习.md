
## 搜索问题

### 第三章 

#### 1.基础概念

+ Closed表 : 已经访问过的节点集合
+ Open表 : 已经扩展但未访问的节点
+ Frontier : 待扩展的节点

#### 2.性能

 + 完备性 : 若问题有解，则一定能求出解
 + 最优性 : 所求出的解一定是最优的
 + 时间复杂度
 + 空间复杂度


#### 一、无信息搜索(盲目搜索)


+ **宽度优先搜索(BFS)**

    + 每次扩展深度最浅的节点，(队列实现)
    + 一般图搜索算法
    + 具有完备性
    + 不一定最优 : 若路径代价相同，或者路径代价随着深度递增，才能保证最优性，**例如代价随深度递减，则可能深度大的解比深度小的解更优**

    + 复杂度 :  设最浅深度为d，后继数为b，则时间、空间复杂度均为O(b^d)


+ **一致代价搜索**

    + 与BFS类似，不过采用优先队列，每次只对当前最优的解进行扩展
    + 与BFS同样属于图搜索
    + 若能保证代价>0,则是完备的
    + 一定最优 : 因为解与深度无关
    + 最坏情况下时空复杂度比BFS大


+ **深度优先搜索(无限状态空间)**

    + 采用图搜索(且是有限空间)则完备，否则均不完备
    + 均不能保证最优性
    + 时间复杂度无上限，O(b^m),m为任意一节点的最大深度，无限状态空间m无限大
    + 空间复杂度 : O(bm)或 O(m)(回溯)

+ **深度受限搜索**

    + 对深度优先搜索加深度限制l

+ **迭代加深的深度优先搜索**

    + 将深度限制从0开始递增，可以用来确定最好的深度界限
    + 与BFS类似(都是先把上层节点全访问完)，但不需要大量的空间需求
    + 当搜索空间很大且不知道所在深度时，迭代加深的深度优先搜索是首选的无信息搜索

+ **双向搜索**

    + 从初始节点和目标节点同时进行，宽度优先搜索(类似以两个点为圆心，不断扩大半径，寻找相交点)
    + 不能保证最优性
    + 适用性有限制，因为不能保证所有场景下都能向前搜索


这里解释一下提到的图搜索和树搜索，与你进行搜索的图形是图还是树没关系

+ 树搜索 : 

```
open <- []  // 已扩展但未访问节点
next <- start // 当前节点

// 只要当前节点不是目标节点就继续循环
while next is not goal {
    // 将当前节点后继节点放入已扩展节点
    add all successors of next to open
    // 将当前节点更新为已扩展节点中的一个，并进行访问
    next <- select one node from open
    // 将访问过的当前节点移除
    remove next from open
}
return next
```

这样做的问题是，如果被移除的节点又可能成为open表中节点的后继节点，那么可能造成死循环(即在图中使用树搜索)

+ 图搜索

```
open <- []
closed <- []
next <- start

while next is not goal {
    add next to closed
    add all successors of next to open, which are not in closed 
    remove next from open
    next <- select from open
}

return next
```

可以看到图搜索在树搜索的基础上添加了一个closed表来记录访问过的节点，即每个节点只能访问一次，这样可以避免出现死循环，不过增加了额外的空间开销



#### 二、有信息搜索(启发式搜索)

引入评价函数f和启发函数h的概念

> h(n): 节点n到最近目标节点的最小代价估计

+ **贪婪最佳优先搜索**

    永远拓展离目标最近的节点，即只依赖启发函数 `f(n) = h(n)`

    + 无完备性
    + 无最优性 : 仅每一步贪婪


+ **A*搜索**

    `f(n) = g(n) + h(n)`

    + `f(n)` : 从初始点到最近目标点 ，且经过节点n的路径最小估计代价
    + `g(n)` : 从初始点到节点n的最小代价
    + `h(n)` : 节点n到最近目标节点的最小代价估计

    保证最优的条件

    + 可采纳性 : 

        启发式的可采纳性 : 指`h(n)`从不会过高的估计代价，即`f(n)`永远不超过实际路径的代价

    + 一致性(单调性) : 

        对于节点n，经过动作a扩展的每个后继结点n'，从节点n到目标节点的代价不大于n到n'的单步代价与n'到目标节点代价的和，即`h(n) <= c(n,a,n') + h(n')`

    
    如果启发式是可采纳的，树搜索最优，如果启发式是一致的，图搜索最优

---

### 第四章 - 局部搜索

给定函数y = f(x),求x使得y最大

##### 1、爬山法-最陡上山版本

本质就是简单循环，不断增加x的值，直到y的临近状态中没有更大值时终止

+ 山峰(局部最大) : 比全局最大值小，比相邻值大
+ 山脊 : ???
+ 高原/山肩 : 比全局最大值小，但与相邻值相同，继续移动可能是局部最大(高原)，也可能继续上升(山肩)

解决办法

**侧向移动** :  在到达高原/山肩时可以继续进行侧向移动，但需要设置连续移动次数限制，避免在高原的情况下陷入死循环

**随机重启爬山法** : 当搜索无法继续时，随机重新生成初始状态，重启爬山，若每次搜索成功概率为p，则重启次数的期望为1/p

##### 2、模拟退火-既上山也下山

移动的选择并不完全依赖结果的好坏，若一次移动使得结果变好，那么则接受，否则则有一定的概率p接受，若移动后情况变坏，则概率p呈指数下降

##### 3、局部束搜索

初始生成K个随机状态，每一步生成每个状态的所有后继，然后K个状态的所有后继中选择最佳的K个后继，重复这个过程

但这样很快又会将答案收敛到一小块区域内，所以出现了**随机束搜索**，即并不是选择最佳的K个后继，而是随机选择K个

##### 4. 遗传算法

是随机束搜索的变形，特点是每个后继不是仅由一个初始状态产生，而是由两个父状态结合产生后继

+ 种群 : 随机生成的K个初始状态，总体称为种群
+ 个体 : 每个状态称为个体,通常用有限的01字符串表示，对于每个个体，都由他的目标函数和适应度函数根据状态的好坏给出适应度，而适应度与个体被选择的概率成正比

根据被选择的概率，随机选择两对进行繁殖，首先选择一个**杂交点**，令状态1杂交点左侧与状态2杂交点右侧结合，令状态1杂交点右侧与状态2杂交点左侧结合，得到后代，对于每个后代 都有小的独立概率随机**变异**


---

### 第五章 - 对抗搜索

[总结](https://blog.csdn.net/BIT1120172185/article/details/80963609)

零和博弈 : 博弈的最终结果，一方获利则另一方必然受损，获利和受损的和为0

假设两个人分别为MAX和MIN，则

+ MAX的任何选择都尽可能使自己获利最大
+ MIN的任何选择都尽可能使MAX获利最小

#### 1、极小极大算法

假设已经遍历出所有可能性，现在要选择出一条对MAX获利最大的方案

将博弈树简化为三层，出手顺序为 MAX -> MIN =>结果

对于所有最终的结果来说，MIN一定会采用当前状态下，可以使结果最小的动作

说明MAX对MIN的行为是可预知的(*即知道自己当前的行为最终会产生什么结果*)，所以MAX在第一步只要选择可预知结果中最大的动作即可

具体理解看书上图

#### 2、α-β剪枝

通过α-β剪枝可以提高极小极大算法的效率

简单说就是每次搜索完一个子树都能得到一个局部最优解，所以对之后子树搜索中出现的更差的解时，可以将整个子树剪掉

具体看书P142


### 第六章 - 约束满足问题(CSP)

#### 约束传播

+ 节点相容 : 对于单个变量中的所有值域，都满足该变量一元约束，则称此变量是节点相容的

+ 弧相容 : 对于单个变量中的所有值域，都满足该变量二元约束，则称此变量是弧相容的  

#### 回溯法


取变量 : 剩余值最少的变量优先
取值 : 变量最少的约束值优先


### 第十四章 - 贝叶斯网络


#### 贝叶斯网络



#### 概率推理


##### 精确推理 : 

+ 枚举
+ 消元

##### 近似推理 : 蒙特卡洛算法

+ 直接采样

    + 先验采样 : 仅根据概率值采样，用采样结果进行估算
    + 拒绝采样 : 对于条件概率P(X|Y) ，先生成样本，然后将Y不满足的样本拒绝掉，在剩余样本中统计X的概率，计算估计概率。
        但是这种方法拒绝了大量的样本，对于复杂的情况不适用
    + 似然采样 : 只生成满足证据变量的样本，对非证据变量进行采样，

        对于每个非证据变量，根据已经采样的父节点的值进行条件采样，对于证据变量，用权值乘以当前概率作为新的权值，并将权值计入自身中进行采样


+ Gibbs采样-马尔科夫链

































