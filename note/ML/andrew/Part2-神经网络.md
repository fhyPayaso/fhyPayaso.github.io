#吴恩达机器学习(8-9)


## 一、 神经网络

### 1. 基本概念

我们之前学的，无论是线性回归还是逻辑回归都有一个缺点，即当特征太多时，计算的负荷会非常大。

假设我们希望训练一个模型来识别视觉对象*（例如识别一张图片上是否是一辆汽车）*，只选用灰度图片*(每个像素只有一个值)*,  同时每张图片采用的都是50x50像素的小图片。 我们将单张图片中的每个值都当做是一个特征 , 那么一个样本会有2500个特征,  如果为了效果更好拟合成二次多项式， 则会有$2500^2/2$(接近300万)个特征,  而普通的逻辑回归模型， 无法处理如此多的特征, 这时就需要使用神经网络模型。


神经网络模型建立在很多神经元之上，每一个神经元又是一个个学习模型。这些**神经元（也叫激活单元，activation unit）**将上一层的特征作为输入，并且根据本身的模型提供一个输出。下图是一个以逻辑回归模型作为自身学习模型的神经元示例，在神经网络中，参数$\theta$又可被成为**权重（weight）**。

![](http://www.ai-start.com/ml2014/images/c2233cd74605a9f8fe69fd59547d3853.jpg)

神经网络模型是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。下图为一个3层的神经网络。

![](http://www.ai-start.com/ml2014/images/8293711e1d23414d0a03f6878f5a2d91.jpg)

其中$x_1 , x_2 , x_3$, 是输入单元（input units），相当于输入的原始数据。 $a_1, a_2, a_3,$ 是中间单元，它们负责将数据进行处理，然后呈递到下一层。 最后是输出单元，它负责计算$h_\theta(x)$。

+ 其中$x_1 , x_2 , x_3$, 是**输入单元（input units）**，相当于输入的原始数据。组成第一层**输入层（Input Layer**）

+  $a_1, a_2, a_3,$ 是**中间单元**，它们负责将数据进行处理，然后呈递到下一层。中间一层被称为**隐藏层（Hidden Layers）**。

+ 最后是**输出单元**，它负责计算$h_\theta(x)$。称为**输出层（Output Layer）**。

需要注意的是, 在计算每一层的时候都需要额外增加一个**偏差单位(bias unit)**


我们可以用数学方法来描述上面的神经网络模型








